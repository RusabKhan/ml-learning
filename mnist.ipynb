{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pytorch_lightning as pl\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_binary_train_label = to_categorical(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential(name=\"mnist\")\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(128, activation=\"relu\", name=\"Hidden-2\"))\n",
    "model.add(Dense(32, activation=\"relu\", name=\"Hidden-3\"))\n",
    "model.add(Dense(10, activation=\"softmax\", name=\"Output\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 8s 4ms/step - loss: 0.3617 - accuracy: 0.8325 - val_loss: 0.0767 - val_accuracy: 0.9131\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0567 - accuracy: 0.9300 - val_loss: 0.0433 - val_accuracy: 0.9422\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0366 - accuracy: 0.9501 - val_loss: 0.0424 - val_accuracy: 0.9439\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0296 - accuracy: 0.9584 - val_loss: 0.0341 - val_accuracy: 0.9503\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0246 - accuracy: 0.9639 - val_loss: 0.0305 - val_accuracy: 0.9579\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, to_binary_train_label, epochs=5,validation_split=0.2,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0270 - accuracy: 0.9617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.027046840637922287, 0.9617000222206116]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, to_categorical(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicted Label: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the image from your local machine\n",
    "image_path = '/Users/rusab1/Downloads/nine.png'  # Replace with the path to your image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert the image to grayscale (if needed) and resize it to 28x28 pixels\n",
    "image = image.convert('L')  # Convert to grayscale\n",
    "image = image.resize((28, 28))\n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "#image_array = image_array / 255.0\n",
    "\n",
    "# Reshape the image to match the input shape expected by the model\n",
    "image_array = image_array.reshape((1,28, 28))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image_array.reshape(28, 28), cmap='gray')  # Show the image in grayscale\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Use the trained model to predict on the loaded image\n",
    "predictions = model.predict(image_array)\n",
    "\n",
    "# Get the predicted label (digit with highest probability)\n",
    "predicted_label = predictions.argmax()\n",
    "\n",
    "print(f\"Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rusab1/Work/learntorch/venv/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"numerical_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " Hidden-2 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " Hidden-3 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104938 (409.91 KB)\n",
      "Trainable params: 104938 (409.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[1.6872086e-07 8.8055431e-06 2.2706623e-05 3.6550578e-04 8.8624109e-04\n",
      "  9.8726625e-05 8.1623517e-09 3.8847898e-04 4.9225640e-05 9.9818015e-01]]\n",
      "Predicted Label: 9\n"
     ]
    }
   ],
   "source": [
    "image_array = test_images[7]\n",
    "\n",
    "\n",
    "\n",
    "#image_array = image_array / 255.0\n",
    "\n",
    "# Reshape the image to match the input shape expected by the model\n",
    "image_array = image_array.reshape((1,28, 28))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image_array.reshape(28, 28), cmap='gray')  # Show the image in grayscale\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Use the trained model to predict on the loaded image\n",
    "predictions = model.predict(image_array)\n",
    "\n",
    "# Get the predicted label (digit with highest probability)\n",
    "predicted_label = predictions.argmax()\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
