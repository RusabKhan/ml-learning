{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 23:46:15.921601: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pytorch_lightning as pl\n",
    "import tensorflow as tf\n",
    "from keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist dataset of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(\"datasets/urdu_numericals.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = dataset[\"image\"]\n",
    "train_labels = dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_binary_train_label = to_categorical(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential(name=\"mnist\")\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(128, activation=\"relu\", name=\"Hidden-2\"))\n",
    "model.add(Dense(32, activation=\"relu\", name=\"Hidden-3\"))\n",
    "model.add(Dense(10, activation=\"softmax\", name=\"Output\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Network below old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential(name=\"mnist\")\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax')) # becuase number range from 0-9 10 in total\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',Precision(name='precision'), Recall(name='recall')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New CNN below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name=\"mnist\")\n",
    "model.add(Conv2D(16, (2, 2), activation='relu', input_shape=(224, 224,1)))  # Changed (3, 3) to (2, 2)\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu'))  # Changed (3, 3) to (2, 2) and channels to 32\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (2, 2), activation='relu'))  # Changed (3, 3) to (2, 2) and channels to 64\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, to_binary_train_label, epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, to_categorical(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/numerical_model_convolutional_2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3_input (InputLayer  [(None, 28, 28, 1)]       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 13, 13, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 3, 3, 32)          2080      \n",
      "                                                                 \n",
      " max_pooling2d_68 (MaxPooli  (None, 3, 3, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 10)                2890      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60714 (237.16 KB)\n",
      "Trainable params: 60714 (237.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model =tf.keras.models.load_model(\n",
    "        \"models/numerical_model_convolutional_2_fine_tuned_urdu.h5\"\n",
    "    ) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'img/three.png'  # Replace with the path to your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicted Label: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the image from your local machine\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert the image to grayscale (if needed) and resize it to 28x28 pixels\n",
    "image = image.convert('L')  # Convert to grayscale\n",
    "image = image.resize((28, 28))\n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "#image_array = image_array / 255.0\n",
    "\n",
    "# Reshape the image to match the input shape expected by the model\n",
    "image_array = image_array.reshape((1,28, 28))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image_array.reshape(28, 28), cmap='gray')  # Show the image in grayscale\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Use the trained model to predict on the loaded image\n",
    "predictions = model.predict(image_array)\n",
    "\n",
    "# Get the predicted label (digit with highest probability)\n",
    "predicted_label = predictions.argmax()\n",
    "#position = int(predicted_label) -1\n",
    "\n",
    "print(f\"Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1000\n",
    "predicted_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in test_images[0:n]:\n",
    "    image_array = t\n",
    "\n",
    "    # Reshape the image to match the input shape expected by the model\n",
    "    image_array = image_array.reshape((1,28, 28))\n",
    "\n",
    "    # Display the image\n",
    "    # plt.imshow(image_array.reshape(28, 28), cmap='gray')  # Show the image in grayscale\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    # Use the trained model to predict on the loaded image\n",
    "    predictions = model.predict(image_array)\n",
    "\n",
    "    # Get the predicted label (digit with highest probability)\n",
    "    predicted_label = predictions.argmax()\n",
    "\n",
    "    #print(predictions)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "    #print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = test_labels[0:n]\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "predicted_labels.shape, tst.shape\n",
    "\n",
    "cm = confusion_matrix(predicted_labels, tst)\n",
    "cm, cm.shape\n",
    "#test_labels,\"in-beteween\", predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_number = 8 # Replace this with the number you want to count\n",
    "#len(test_images)\n",
    "# Calculate count for the desired number\n",
    "count_of_desired_number = np.sum(predicted_labels == desired_number)\n",
    "\n",
    "#print(len(predicted_labels))\n",
    "\n",
    "print(f\"Count of {desired_number}: {count_of_desired_number}\")\n",
    "\n",
    "accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "np.trace(cm) #sum of diagonal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(predicted_labels, tst)\n",
    "\n",
    "# Identify misclassifications with counts greater than 1\n",
    "misclassified_indices = np.where(cm > 0)\n",
    "\n",
    "# Display the confusion matrix and its shape\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(cm)\n",
    "print(\"Shape of Confusion Matrix:\", cm.shape)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Define colors for the plot\n",
    "cmap = plt.cm.Blues\n",
    "# Set the color for misclassifications\n",
    "cmap.set_under('green')\n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0.1)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "# Adding axis labels \n",
    "classes = np.unique(tst)\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Adding annotations for misclassifications with counts > 1\n",
    "thresh = cm.max() / 2.0\n",
    "for i, j in zip(*misclassified_indices):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## see mnist data images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(1, 11):  # Display 10 sample images\n",
    "    plt.subplot(2, 5, i)\n",
    "    plt.imshow(train_images[i], cmap='gray')\n",
    "    plt.title(f\"Label: {train_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
