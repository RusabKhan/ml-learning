{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['track_id', 'track_name', 'track_artist', 'track_popularity',\n",
       "       'track_album_id', 'track_album_name', 'track_album_release_date',\n",
       "       'playlist_name', 'playlist_id', 'playlist_genre', 'playlist_subgenre',\n",
       "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       'duration_ms'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/rusab1/Work/learntorch/datasets/spotify_songs.csv')  # Replace 'your_dataset.csv' with your file path\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        66\n",
       "1        67\n",
       "2        70\n",
       "3        60\n",
       "4        69\n",
       "         ..\n",
       "32828    42\n",
       "32829    20\n",
       "32830    14\n",
       "32831    15\n",
       "32832    27\n",
       "Name: track_popularity, Length: 32833, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_artist = data.pop('track_popularity')\n",
    "track_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rusab1/Work/learntorch/spotify.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rusab1/Work/learntorch/spotify.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mget_dummies(data)\n",
      "File \u001b[0;32m~/Work/learntorch/venv/lib/python3.11/site-packages/pandas/core/reshape/encoding.py:209\u001b[0m, in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    205\u001b[0m     with_dummies \u001b[39m=\u001b[39m [data\u001b[39m.\u001b[39mselect_dtypes(exclude\u001b[39m=\u001b[39mdtypes_to_encode)]\n\u001b[1;32m    207\u001b[0m \u001b[39mfor\u001b[39;00m col, pre, sep \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(data_to_encode\u001b[39m.\u001b[39mitems(), prefix, prefix_sep):\n\u001b[1;32m    208\u001b[0m     \u001b[39m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     dummy \u001b[39m=\u001b[39m _get_dummies_1d(\n\u001b[1;32m    210\u001b[0m         col[\u001b[39m1\u001b[39;49m],\n\u001b[1;32m    211\u001b[0m         prefix\u001b[39m=\u001b[39;49mpre,\n\u001b[1;32m    212\u001b[0m         prefix_sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m    213\u001b[0m         dummy_na\u001b[39m=\u001b[39;49mdummy_na,\n\u001b[1;32m    214\u001b[0m         sparse\u001b[39m=\u001b[39;49msparse,\n\u001b[1;32m    215\u001b[0m         drop_first\u001b[39m=\u001b[39;49mdrop_first,\n\u001b[1;32m    216\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    218\u001b[0m     with_dummies\u001b[39m.\u001b[39mappend(dummy)\n\u001b[1;32m    219\u001b[0m result \u001b[39m=\u001b[39m concat(with_dummies, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Work/learntorch/venv/lib/python3.11/site-packages/pandas/core/reshape/encoding.py:330\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[0;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m     eye_dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbool_\n\u001b[0;32m--> 330\u001b[0m dummy_mat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49meye(number_of_cols, dtype\u001b[39m=\u001b[39;49meye_dtype)\u001b[39m.\u001b[39;49mtake(codes, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mT\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dummy_na:\n\u001b[1;32m    333\u001b[0m     \u001b[39m# reset NaN GH4446\u001b[39;00m\n\u001b[1;32m    334\u001b[0m     dummy_mat[codes \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32833 entries, 0 to 32832\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   track_id                  32833 non-null  object \n",
      " 1   track_name                32828 non-null  object \n",
      " 2   track_artist              32828 non-null  object \n",
      " 3   track_album_id            32833 non-null  object \n",
      " 4   track_album_name          32828 non-null  object \n",
      " 5   track_album_release_date  32833 non-null  object \n",
      " 6   playlist_name             32833 non-null  object \n",
      " 7   playlist_id               32833 non-null  object \n",
      " 8   playlist_genre            32833 non-null  object \n",
      " 9   playlist_subgenre         32833 non-null  object \n",
      " 10  danceability              32833 non-null  float64\n",
      " 11  energy                    32833 non-null  float64\n",
      " 12  key                       32833 non-null  int64  \n",
      " 13  loudness                  32833 non-null  float64\n",
      " 14  mode                      32833 non-null  int64  \n",
      " 15  speechiness               32833 non-null  float64\n",
      " 16  acousticness              32833 non-null  float64\n",
      " 17  instrumentalness          32833 non-null  float64\n",
      " 18  liveness                  32833 non-null  float64\n",
      " 19  valence                   32833 non-null  float64\n",
      " 20  tempo                     32833 non-null  float64\n",
      " 21  duration_ms               32833 non-null  int64  \n",
      "dtypes: float64(9), int64(3), object(10)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
