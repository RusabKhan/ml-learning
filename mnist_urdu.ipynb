{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 23:35:47.996394: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pytorch_lightning as pl\n",
    "import tensorflow as tf\n",
    "from keras.metrics import Precision, Recall\n",
    "from keras.layers import Reshape, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D, Concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (95, 224, 224)\n",
      "Labels shape: (95,)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_png_images_from_folder(folder_path, target_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".png\"):\n",
    "            label = int(filename[0])  # Assuming the label is the first character in the filename\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize(target_size)  # Resize the image to a consistent size\n",
    "            images.append(np.array(img))\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Replace 'path/to/your/images' with the actual path to your folder containing .png files\n",
    "image_folder_path = 'img/urdu_numerals/'\n",
    "images, labels = load_png_images_from_folder(image_folder_path)\n",
    "\n",
    "# Print the shape of the created dataset\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"datasets/urdu_numericals.npz\", image=images, label = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 13, 13, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93322 (364.54 KB)\n",
      "Trainable params: 93322 (364.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model =tf.keras.models.load_model(\n",
    "        \"models/numerical_model_convolutional.h5\"\n",
    "    ) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_x = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_3\n",
      "max_pooling2d_2\n",
      "conv2d_4\n",
      "max_pooling2d_3\n",
      "conv2d_5\n",
      "flatten_1\n",
      "dense_2\n",
      "dense_3\n"
     ]
    }
   ],
   "source": [
    "for m in model.layers:\n",
    "    print(m.name)\n",
    "new_model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnew_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Work/learntorch/venv/lib/python3.11/site-packages/keras/src/engine/training.py:3506\u001b[0m, in \u001b[0;36mModel.summary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[1;32m   3475\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[1;32m   3476\u001b[0m \n\u001b[1;32m   3477\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[1;32m   3504\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m-> 3506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3509\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3510\u001b[0m     )\n\u001b[1;32m   3511\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[1;32m   3512\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3513\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3518\u001b[0m     layer_range\u001b[38;5;241m=\u001b[39mlayer_range,\n\u001b[1;32m   3519\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 223, 223, 32)      160       \n",
      "                                                                 \n",
      " max_pooling2d_newmodel (Ma  (None, 111, 111, 32)      0         \n",
      " xPooling2D)                                                     \n",
      "                                                                 \n",
      " max_pooling2d_2_new_1 (Max  multiple                  0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " conv2d_4_new_2_new_2_new_2  multiple                  18496     \n",
      " _new_2_new_2_new_2_new_2 (                                      \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " max_pooling2d_3_new_3_new_  multiple                  0         \n",
      " 3_new_3_new_3_new_3_new_3                                       \n",
      " (MaxPooling2D)                                                  \n",
      "                                                                 \n",
      " conv2d_5_new_4_new_4_new_4  multiple                  36928     \n",
      " _new_4_new_4_new_4 (Conv2D                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      " Conv2D_2_new (Conv2D)       (None, 24, 24, 32)        2080      \n",
      "                                                                 \n",
      " maxpo0ling_new (MaxPooling  (None, 24, 24, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_new (Flatten)       (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_final_new (Dense)     (None, 64)                1179712   \n",
      "                                                                 \n",
      " dense_final_new_new (Dense  (None, 10)                650       \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1238026 (4.72 MB)\n",
      "Trainable params: 1182602 (4.51 MB)\n",
      "Non-trainable params: 55424 (216.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = Sequential()\n",
    "new_model.add(Conv2D(32, (2, 2), activation='relu', input_shape=(224, 224,1)))\n",
    "new_model.add(MaxPooling2D(pool_size=(2, 2), name='max_pooling2d_newmodel'))   # Changed (3, 3) to (2, 2)\n",
    "\n",
    "for idx, layer in enumerate(model.layers):\n",
    "    if idx not in [0,5,6,7]:\n",
    "        # Append the index to the layer name to make it unique\n",
    "        new_layer_name = f\"{layer.name}_new_{idx}\"\n",
    "        layer._name = new_layer_name\n",
    "        layer.trainable = False\n",
    "        new_model.add(layer)\n",
    "\n",
    "new_model.add(Conv2D(32, (1, 1), activation='relu',name=\"Conv2D_2_new\"))\n",
    "new_model.add(MaxPooling2D(1, 1,name=\"maxpo0ling_new\"))\n",
    "new_model.add(Flatten(name=\"flatten_new\"))\n",
    "new_model.add(Dense(64, activation='softmax',name=\"dense_final_new\"))\n",
    "new_model.add(Dense(10, activation='softmax', name=\"dense_final_new_new\"))\n",
    "\n",
    "new_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for layer in new_model.layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x16f025010>\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x16f00a1d0>\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x16d680c10>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x16d78dc10>\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x16d78fb10>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x16cf91c50>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x16f02e810>\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x16ef16510>\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x16f05f310>\n",
      "<keras.src.layers.core.dense.Dense object at 0x16f0aca10>\n",
      "<keras.src.layers.core.dense.Dense object at 0x16e1a0610>\n"
     ]
    }
   ],
   "source": [
    "for layer in new_model.layers:\n",
    "    print(layer)\n",
    "var1 = new_model.layers[0].input\n",
    "\n",
    "# new_model = tf.keras.Model(inputs=var1, outputs=final_layer)\n",
    "#new_model.build()\n",
    "new_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 663ms/step - loss: 2.0653 - accuracy: 0.5263 - val_loss: 2.1054 - val_accuracy: 0.3158\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 476ms/step - loss: 2.0587 - accuracy: 0.5263 - val_loss: 2.1251 - val_accuracy: 0.2632\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 462ms/step - loss: 2.0522 - accuracy: 0.5263 - val_loss: 2.1378 - val_accuracy: 0.2632\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 475ms/step - loss: 2.0476 - accuracy: 0.5132 - val_loss: 2.1347 - val_accuracy: 0.3684\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 471ms/step - loss: 2.0430 - accuracy: 0.5789 - val_loss: 2.1193 - val_accuracy: 0.3684\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 468ms/step - loss: 2.0387 - accuracy: 0.5789 - val_loss: 2.0951 - val_accuracy: 0.3684\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 472ms/step - loss: 2.0342 - accuracy: 0.5789 - val_loss: 2.0799 - val_accuracy: 0.4211\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 466ms/step - loss: 2.0299 - accuracy: 0.5789 - val_loss: 2.0757 - val_accuracy: 0.4737\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 462ms/step - loss: 2.0258 - accuracy: 0.5789 - val_loss: 2.0729 - val_accuracy: 0.4211\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 473ms/step - loss: 2.0215 - accuracy: 0.5789 - val_loss: 2.0703 - val_accuracy: 0.4211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16f0ce3d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(images,labels_x, batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rusab1/Work/learntorch/venv/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "new_model.save(\"models/numerical_model_convolutional_2_fine_tuned_urdu_224.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
